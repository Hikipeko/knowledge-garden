### 2.1 数据操作

```python
# concateneate, dim=i为形状的第i个元素
torch.cat((X, Y), dim=0)
X[0:2, :] = 12

# 节省内存
Y = Y + X # No 为Y分配了新的内存
Z = torch.zeros_like(Y)
Z[:] = X + Y
# 或者
Y += X
```

### 2.5 自动微分

```python
x = ...
x.requires_grad_(True)
y = f(x)
y.backward()
x.grad
x.grad.zero_()
```

### 2.7 查阅文档

```python
help(np.ones)
```